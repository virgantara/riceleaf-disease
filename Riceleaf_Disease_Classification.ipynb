{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3AM6dLvhaUW"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PDurcF7_ZmB6"
   },
   "outputs": [],
   "source": [
    "import os #menejemenisasi file dan folder\n",
    "# import cv2 \n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image #library clean data\n",
    "#library untuk menampilkan gambar\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#library tensorflow untuk pelatihan model \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #library untuk augmentasi gambar\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN2ioi7Rhh5C"
   },
   "source": [
    "# List all data in each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "um0v3hQaZqtJ"
   },
   "outputs": [],
   "source": [
    "#Direktori data\n",
    "base_dir = 'dataset'\n",
    "#Direktori data daun sakit\n",
    "blast_dir = os.path.join(base_dir, 'full/LeafBlast')\n",
    "#Direktori data daun sehat\n",
    "brownspot_dir = os.path.join(base_dir, 'full/BrownSpot')\n",
    "#Direktori data daun sehat\n",
    "hispa_dir = os.path.join(base_dir, 'full/Hispa')\n",
    "healthy_dir = os.path.join(base_dir, 'full/Healthy')\n",
    "#Mengambil semua anama file dalam masing-masing direktori\n",
    "balst_fnames = os.listdir(blast_dir )\n",
    "brownspot_fnames = os.listdir(brownspot_dir)\n",
    "hispa_fnames = os.listdir(hispa_dir)\n",
    "healthy_fnames = os.listdir(healthy_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wf5gCglFZr0j",
    "outputId": "0a21bb91-2cdd-461b-fd01-03e07f602750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data Blast: 523\n",
      "total data Brownspot: 523\n",
      "total data Hispa: 523\n",
      "total data healthy: 523\n"
     ]
    }
   ],
   "source": [
    "#check file\n",
    "print('total data Blast:',len(os.listdir(blast_dir)))\n",
    "print('total data Brownspot:',len(os.listdir(brownspot_dir)))\n",
    "print('total data Hispa:',len(os.listdir(hispa_dir)))\n",
    "print('total data healthy:',len(os.listdir(healthy_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nog1AudjhmFS"
   },
   "source": [
    "# Preview some samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "6gNMpakfZ9a4",
    "outputId": "3c0f8b40-7ede-46e5-c59d-a4c5b218449b"
   },
   "outputs": [],
   "source": [
    "# cols = 4\n",
    "# rows = 3\n",
    "\n",
    "# pic_index = 0\n",
    "# #menampilkan gambar file\n",
    "# img = plt.gcf()\n",
    "# img.set_size_inches(cols*4, rows*3) \n",
    "\n",
    "# pic_index+=4\n",
    "\n",
    "# #menyimpan ke dalam list nama file yang akan ditampilkan\n",
    "# show_blast_img = [os.path.join(blast_dir, fname)\n",
    "#                       for fname in balst_fnames[pic_index-4:pic_index] \n",
    "#                     ]\n",
    "\n",
    "# show_brownspot_img = [os.path.join(brownspot_dir, fname)\n",
    "#                       for fname in brownspot_fnames[pic_index-4:pic_index]\n",
    "#                     ]\n",
    "# show_hispa_img = [os.path.join(hispa_dir, fname)\n",
    "#                       for fname in hispa_fnames[pic_index-4:pic_index]\n",
    "#                     ]\n",
    "# for i, img_path in enumerate(show_blast_img+show_brownspot_img+show_hispa_img):\n",
    "#     sp = plt.subplot(rows, cols, i + 1)\n",
    "#     sp.axis('off')\n",
    "\n",
    "#     image = mpimg.imread(img_path)\n",
    "#     plt.imshow(image)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W5dmPHQhp1L"
   },
   "source": [
    "# Load Image using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAQflt5maBEB",
    "outputId": "cb13fdef-f0db-4457-ea07-b7c605e4bf9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1676 images belonging to 4 classes.\n",
      "Found 416 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (200, 200)\n",
    "DATA_DIR = os.path.join(base_dir, 'full')\n",
    "#VALID_DATA_DIR = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    shuffle=False,\n",
    "    subset='training',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    shuffle=False,\n",
    "    subset='validation',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MdCJ9JraTQy",
    "outputId": "7b5611cb-7d3c-4020-9e9c-ddab0bac1cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BrownSpot': 0, 'Healthy': 1, 'Hispa': 2, 'LeafBlast': 3}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPE9mRb3huEx"
   },
   "source": [
    "# Our model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1RqWKbhTaT1S"
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    # accuracy plots\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.plot(\n",
    "        train_acc, color='green', linestyle='-', \n",
    "        label='train accuracy'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_acc, color='blue', linestyle='-', \n",
    "        label='validataion accuracy'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    filepath = os.path.join(base_dir, 'figures')\n",
    "    plt.savefig(filepath+'/accuracy.png')\n",
    "    plt.show()\n",
    "    # loss plots\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.plot(\n",
    "        train_loss, color='orange', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(filepath+'/loss.png')\n",
    "    plt.show()\n",
    "\n",
    "def get_model(train=False):\n",
    "  \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (224,224,3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation= 'relu'),\n",
    "        tf.keras.layers.Dense(512, activation= 'relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation= 'softmax')\n",
    "    ])\n",
    "\n",
    "  #menampilkan summary/keterangan dari model\n",
    "  \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                metrics=['accuracy'])\n",
    "    history = None\n",
    "    filepath = os.path.join(base_dir, 'models')\n",
    "    if train:\n",
    "    \n",
    "        checkpoint_path = filepath+\"/training_1/cp.ckpt\"\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "        # Create a callback that saves the model's weights\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        verbose=1)\n",
    "\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "            steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=valid_generator,\n",
    "            callbacks=[cp_callback],\n",
    "            validation_steps= valid_generator.samples // BATCH_SIZE,\n",
    "            verbose=1\n",
    "            )\n",
    "        train_loss = history.history['loss']\n",
    "        train_acc = history.history['accuracy']\n",
    "        valid_loss = history.history['val_loss']\n",
    "        valid_acc = history.history['val_accuracy']\n",
    "\n",
    "        save_plots(train_acc, valid_acc, train_loss, valid_loss)\n",
    "        model.save(save_format=\"h5\",filepath=filepath+\"/modelku\")\n",
    "    else:\n",
    "        history = tf.keras.models.load_model(filepath+\"/modelku\")\n",
    "    \n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T0PhgN0hxPR"
   },
   "source": [
    "# Training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIz7Jn95hzD9"
   },
   "source": [
    "# Performance measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dG-8CqtadNP",
    "outputId": "0418d3c0-15b5-4c66-dc4e-66ec12fdf499"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 21:49:34.368586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-09 21:49:34.474465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.475360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-01-09 21:49:34.475930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-01-09 21:49:34.480099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-01-09 21:49:34.483474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-01-09 21:49:34.484326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-01-09 21:49:34.489191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-01-09 21:49:34.492838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-01-09 21:49:34.504532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-09 21:49:34.504854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.505872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.506621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2022-01-09 21:49:34.507938: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-01-09 21:49:34.546079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2022-01-09 21:49:34.548239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5585cd65f300 executing computations on platform Host. Devices:\n",
      "2022-01-09 21:49:34.548302: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-09 21:49:34.548818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.549926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-01-09 21:49:34.550040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-01-09 21:49:34.550097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-01-09 21:49:34.550148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-01-09 21:49:34.550201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-01-09 21:49:34.550251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-01-09 21:49:34.550301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-01-09 21:49:34.550352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-09 21:49:34.550557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.554855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.555672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2022-01-09 21:49:34.555791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-01-09 21:49:34.762672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-09 21:49:34.762746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2022-01-09 21:49:34.762789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2022-01-09 21:49:34.763276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.764369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.765302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-09 21:49:34.766195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3062 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-01-09 21:49:34.771453: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5585cf955fc0 executing computations on platform CUDA. Devices:\n",
      "2022-01-09 21:49:34.771507: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce GTX 1050 Ti, Compute Capability 6.1\n",
      "2022-01-09 21:50:03.959575: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 1 of 53\n",
      "2022-01-09 21:50:19.751794: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 2 of 53\n",
      "2022-01-09 21:50:24.837724: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 3 of 53\n",
      "2022-01-09 21:50:30.408277: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 5 of 53\n",
      "2022-01-09 21:50:42.990463: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 8 of 53\n",
      "2022-01-09 21:50:53.843648: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 10 of 53\n",
      "2022-01-09 21:51:02.275950: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 11 of 53\n",
      "2022-01-09 21:51:13.150424: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 13 of 53\n",
      "2022-01-09 21:51:28.870670: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 14 of 53\n",
      "2022-01-09 21:51:37.549716: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 15 of 53\n",
      "2022-01-09 21:51:51.206199: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 16 of 53\n",
      "2022-01-09 21:52:05.422524: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 17 of 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 21:52:21.345857: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 18 of 53\n",
      "2022-01-09 21:52:32.359814: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 19 of 53\n",
      "2022-01-09 21:52:44.566020: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 20 of 53\n",
      "2022-01-09 21:52:58.643450: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 21 of 53\n",
      "2022-01-09 21:53:11.712035: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 22 of 53\n",
      "2022-01-09 21:53:25.302609: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 23 of 53\n",
      "2022-01-09 21:53:34.297075: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 24 of 53\n",
      "2022-01-09 21:53:50.146865: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 25 of 53\n",
      "2022-01-09 21:53:58.794007: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 26 of 53\n",
      "2022-01-09 21:54:12.697655: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 27 of 53\n",
      "2022-01-09 21:54:26.101434: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 28 of 53\n",
      "2022-01-09 21:54:40.714972: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 29 of 53\n",
      "2022-01-09 21:54:54.524524: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 30 of 53\n",
      "2022-01-09 21:55:06.193968: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 31 of 53\n",
      "2022-01-09 21:55:20.732317: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 32 of 53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = get_model(train=True)\n",
    "\n",
    "if model is not None:\n",
    "    # model.summary()\n",
    "\n",
    "    # test_labels = valid_generator.labels\n",
    "    loss, acc = model.evaluate(valid_generator)\n",
    "    print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "\n",
    "\n",
    "# print(valid_generator.labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Riceleaf Disease Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "deepEnv",
   "language": "python",
   "name": "deepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
